
"""CHAT-BOT WORKING

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/191D138vB4C66azYPPeXeRymUhUz77Xqp

# Чем мы будем заниматься на интенсиве?

**День 1:** Знакомимся с Python и архитектурой умного чат-бота

https://live.skillbox.ru/webinars/code/znakomimsya-s-python-i-arkhitekturoi-umnogo-chat-bota190922/
*   Что такое NLU и как компьютер понимает естественную речь.
*   Архитектура «умных» чат-ботов.
*   Начало работы с Python.
*   Типы и структуры данных Python. Циклы и функции.

**День 2:** Учим бота на Python понимать текст 

https://live.skillbox.ru/webinars/code/uchim-bota-na-python-ponimat-tekst200922/
*   Подготовка дата-сета.
*   Алгоритмы сравнения текстов.
*   Векторизация.
*   Обучение машинной модели.
*   Измерение качества классификатора и интеграция в чат-бота.

**День 3:** Искусственный интеллект на Python: подводим итоги

https://live.skillbox.ru/webinars/code/iskusstvennyi-intellekt-na-python-podvodim-itogi210922/
*   Создание Telegram-бота через @BotFather.
*   Запуск и подключение Python-приложения.



<img src='https://drive.google.com/uc?export=view&id=1jh8IXsRZMwODB7Yk_ZH7pR1laJaQlaly' height=300>

# День 1

## ВЕРСИЯ 1: Простейший Чат-бот
`{Вопрос на входе}` => `{Алгоритм ответа}` => `{Ответ на выходе}`

---
Простейший алгоритм — это поиск по базе известных вопросов и ответов.
"""

import random

intents = {
    'hello': {
        'examples': ['Хелло', "Привет", "Здравствуйте"],
        'responses': ['Добрый день!', "Как дела?", "Как настроение?"]
    },
    'weather': {
        'examples': ['Какая погода?', 'Что за окном', "Во что одеваться?"],
        'responses': ['Погода отличная!', "У природы нет плохой погоды!"],
    }
}
 
# input = ввод данных от пользователя
# random.choice = выбор случайного элемента из списка
# print = вывод на экран

text = input("Ваша реплика: ")

print (text)

if text == 'Какая погода?':
  print('weather')

intents['hello']['examples']

text = input ("Ваша реплика: ")

for intent_name in intents:
    for example in intents[intent_name]['examples']:
        if text == example:
           answer = random.choice(intents[intent_name]['responses'])
           print (answer)

"""Визуализация кода: https://pythontutor.com/visualize

### Алгоритм ответа
1.   Если вопрос это что-то вроде "*Привет*" или "*Хеллоу*"
2.   То ответить случайной фразой вроде "**Йоу**", "**Приветики**" или "**Здрасте**"

Сложность — в том чтобы сравнить **Текст Пользователя** и текст в программе.
"""

import re #regular expression
import nltk #от опечаток

def clean_up(text):
    # преобразуем слово к нижнему регистру
    text = text.lower()
    # описываем текстовый шаблон для удаления: "все, что не является буквой \w или пробелом \s"
    re_not_word = r'[^\w\s]'
    # заменяем в исходном тексте то, что соответствует шаблону, на пустой текст (удаляем)
    text = re.sub(re_not_word, '', text)
    # возвращаем очищенный текст
    return text.lower()

def text_match(user_text, example):
    # допишем функцию так, чтобы все примеры ниже работали
    user_text = clean_up(user_text)
    example = clean_up(example)
    # A.find(B) - возвращает номер буквы, с которой идет текст B внутри текста А
    # find возвращает -1 в случае, если ничего не нашла
    if user_text.find(example) != -1:
      return True

    example_len = len(example)
    distance = nltk.edit_distance(user_text, example) / example_len

    return distance < 0.4

# Тексты совпадают
text_match("Привет", "Привет")

# Разный регистр (ToDo: lower)
text_match("ПрИВеТ", "Привет")

# Лишние символы (ToDo: regular expressions)
text_match("Привет!!!", "Привет")

# Лишние слова (ToDo: find)
text_match("Привет, как дела", "Привет")

# Опечатки (ToDo: levenstein)
text_match("Превет", "Привет")

nltk.edit_distance('Превет', 'Привет')

nltk.edit_distance('Привет, как дела', 'Привет')

user_text = 'Превит'
example = 'Привет'
example_len = len(example)

nltk.edit_distance(user_text, example) / example_len

"""### ВЕРСИЯ 2: Определение намерения (intent) пользователя

"""

intents = {
    'hello': {
        'examples': ['Хелло', "Привет", "Здравствуйте"],
        'responses': ['Добрый день!', "Как дела?", "Как настроение?"],
    },
    'weather': {
        'examples': ['Какая погода?', 'Что за окном', "Во что одеваться?"],
        'responses': ['Погода отличная!', "У природы нет плохой погоды!"],
    },
    'undefined': {
        'examples': [],
        'responses': ['Извините, я еще не знаю таких слов(', "Давайте поговорим о чем-то другом!"],
    },
    'exit': {
        'examples': ['Выход', 'Пока', 'До свидания'],
        'responses': ["До свидания!", "До скорого!", "Пока-пока!"],
    }
}

# Определить намерение по тексту
# "Чем занят" => "how-are-you"
def get_intent(text):
  # Проверить все существующие intent'ы
    # Какой-нибудь один будет иметь example похожий на text
    # Проверить все examples
    for intent_name in intents:
      for example in intents[intent_name]['examples']:
        if text_match(text, example):
          return intent_name
    return 'undefinded'
# "hello" => "Йоу"
# Берет случайны response для данного intent'а
def get_response(intent):
    return random.choice(intents[intent]['responses'])

get_intent('Привет')

def bot(text):
  intent = get_intent(text)
  answer = get_response(intent)
  return answer

text = 'привет'
while get_intent(text) != 'exit':
  text = input ('< ')
  print ('>', bot(text))

"""# День 2

## ВЕРСИЯ 3: Классификация текстов ML-моделью

### Шаг 1: собираем данные, на которых будет учиться модель

Задача: Научить Модель опеределять интент по тексту пользователя

**Классификация текстов**


Фраза на вход => Модель предсказывает интент фразы

Входные данные (Фразы, X)
Выходные данные (Интенты, y)

Модель обучится на наших примерах и сможет предсказывать интенты по фразе.
"""

# Скачаем файл с большим количеством примеров для обучения
import os
import urllib.request

#url = "https://drive.google.com/uc?export=download&confirm=no_antivirus&id=10sv5u2ZUSMka_YdUP1BcVJ4oRqiUeZU3"
filename = "intents_dataset.json"
#urllib.request.urlretrieve(url, filename)

# Считываем файл в словарь
import json

with open(filename, 'r', encoding='UTF-8') as file:
  data = json.load(file)

len(data)

"""Составляем 2 массива:
* **X** - входные фразы (то, что модель будет получать от пользователя)
* **y** - интенты (то, что модель будет учиться прогнозировать)

<img src='https://drive.google.com/uc?export=view&id=1u3wiw_dSsYbEyGPfu3pj_mMHMnVVINS6' height=450 border='1' alt=''>
"""

# пробегаем по всему словарю - берем пары ключ-значение и раскладываем по двум спискам
# сначала берем пары name, intent из словаря
# потом для каждого элемента в examples и responses добавляем в X элемент, 
# а в y параллельно кладем name - название корневого интента
X = []
y = []

for name in data:
  for phrase in data[name]['examples']:
    X.append(phrase)
    y.append(name)
  for phrase in data[name]['responses']:
    X.append(phrase)
    y.append(name)

len(X)

"""### Шаг 2: преобразуем слова в числа

**Векторизация** - процесс кодирования слова в набор чисел

[sklearn.CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)

1. На вход подается большой набор фраз
2. Векторайзер обучается (каждому слову выделяется отдельная ячейка, куда будет вставляться код - число, сколько раз слово встретилось во фразе)
3. Векторайзер готов работать с новыми текстами

**Пример**
```
1. Набор текстов = {
  "мама мыла раму", 
  "Саша мыла раму",
}
```

```
2. Обучение
мама -> 1, мыла -> 2, раму -> 3, Саша -> 4
  "мама мыла раму" = [1, 1, 1, 0]
  "Саша мыла раму" = [0, 1, 1, 1]
```
```
3. Векторизация
"мама мама мама" = [3, 0, 0, 0]
"как мама мыла раму" = [1, 1, 1, 0]
"шла Саша по шоссе" = [0, 0, 0, 1]
```
"""

from sklearn.feature_extraction.text import CountVectorizer

vectorizer = CountVectorizer()
vectorizer.fit(["мама мыла раму", "Саша мыла раму",]) # Обучаем векторайзер

print(vectorizer.get_feature_names_out())
print("мама мама мама ->", vectorizer.transform(["мама мама мама"]).toarray())
print("шла Саша по шоссе ->", vectorizer.transform(["шла Саша по шоссе"]).toarray())

"""Векторизуем наши фразы X"""

vectorizer = CountVectorizer()
vectorizer.fit(X)

X_vec = vectorizer.transform(X)

vectorizer.transform(['какая погода']).toarray()

vectorizer.get_feature_names_out()

"""### Шаг 3: обучаем классификатор текстов"""

from sklearn.neural_network import MLPClassifier # Импортируем
# Создаем модель
model = MLPClassifier()
# Обучаем модель
model.fit(X_vec, y)

test_vec = vectorizer.transform(['Как дела?'])
model.predict(test_vec)

model.predict(test_vec)[0]

"""### Шаг 4: оцениваем качество

**Accuracy** $= \frac{n\ угаданных}{N\ всего}$ — доля правильных ответов (больше - лучше)

_Вопрос на внимательность: какое максимальное и минимальное значение метрики может быть, исходя из формулы выше?_
"""

model.score(X_vec, y)  # Качество на тренировочной выборке = accuracy / больше = лучше

"""### Шаг 5: пишем функцию для получения интента с помощью ML"""

def get_intent(text):
    text_vec = vectorizer.transform([text])
    intent = model.predict(text_vec)[0]
    return intent

get_intent("привет, как дела?")

get_intent("давай анекдот")

data['talks_dogs']

data['exit'] = intents['exit']

def get_response(intent):
    return random.choice(data[intent]['responses'])

def bot(text):
    intent = get_intent(text)
    answer = get_response(intent)
    return answer

data['bye']

text = ""
while get_intent(text) != 'bye':
    text=input('< ')
    print('>', bot(text))

"""# День 3

Бот в Телеграм

Библиотека [python-telegram-bot](https://python-telegram-bot.org/)

Токен получаем у телеграм-бота @BotFather
"""


import os
import random
import json
import urllib.request
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.neural_network import MLPClassifier

# Загружаем файл с диалогами для обучения модели
url = "https://drive.google.com/uc?export=download&confirm=no_antivirus&id=1Uj4WFvaQkksq1BTi-xeYnmiUbVpRPuIm"
filename = "intents_dataset.json"
urllib.request.urlretrieve(url, filename)

# Считываем файл в словарь
with open(filename, 'r', encoding='UTF-8') as file:
    data = json.load(file)

# Создаем массивы фраз и интентов для обучения
X = []
y = []

for name in data:
    for phrase in data[name]['examples']:
        X.append(phrase)
        y.append(name)
    for phrase in data[name]['responses']:
        X.append(phrase)
        y.append(name)

# Векторизуем наши фразы X
vectorizer = CountVectorizer()
vectorizer.fit(X)
X_vec = vectorizer.transform(X)

# Создаем и обучаем модель
model_mlp = MLPClassifier()
model_mlp.fit(X_vec, y)

MODEL = model_mlp

def get_intent(text):
    # сначала преобразуем текст в числа
    text_vec = vectorizer.transform([text])
    # берем элемент номер 0 - для того, чтобы избавиться от формата "список", который необходим для векторизации и машинного обучения
    return model_mlp.predict(text_vec)[0] 

def get_response(intent):
    return random.choice(data[intent]['responses'])

def bot(text):
    intent = get_intent(text)
    answer = get_response(intent)
    return answer


import nest_asyncio
nest_asyncio.apply()

try:
    with open('secret_file.txt', 'r') as f:
        TOKEN = f.read()
except:
    print('Это файл с токеном спикера. Вам нужно вставить свой токен в ячейку ниже')

TOKEN = '5660077746:AAGcrge50E-xSQn0hz6eUsVuQpRsrVyrRPA'

#  Update - информация полученная с сервера (новые сообщения, новые контакты)
#  С сервера регулярно регулярно приходят Update'ы с новой информацией
from telegram import Update 
from telegram.ext import ApplicationBuilder #  Инструмент чтобы создавать и настраивать приложение (телеграм бот)
from telegram.ext import MessageHandler #  Handler (обработчик) - создать реакцию (функцию) на действие

from  telegram.ext import filters

# Функция для MessageHandler'а, вызывать ее при каждом сообщении боту
async def reply(update: Update, context) -> None:
      user_text = update.message.text
      reply = bot(user_text)
      print('<', user_text)
      print('>', reply)

      await update.message.reply_text(reply)


# Создаем объект приложения - связываем его с токеном
app = ApplicationBuilder().token(TOKEN).build()

# Создаем обработчик текстовых сообщений
handler = MessageHandler(filters.Text(), reply)

# Добавляем обработчик в приложение
app.add_handler(handler)

# Запускаем приложение: бот крутится, пока крутится колесико выполнения слева ячейки)
app.run_polling()